exp_name: 'DIRL+CCR_levir_skip_only_2'
gpu_id: [0]
logger:
    display_id: 9909
model:
    transformer_encoder:
        input_dim: 2048
        feat_dim: 1024
        emb_dim: 512
        att_dim: 512
        att_head: 8
        att_layer: 2
        dim: 128
    transformer_decoder:
        input_dim: 2048
        word_dim: 300
        att_dim: 512
        att_head: 8
        att_layer: 2
        vocab_size: 860
        seq_length: 42
        share_wd_cls_weight: False
        label_smoothing: 0.0
    auxiliary:
        use_skip_connection: True
        use_mask_in_decoder: False
        num_blocks: 2  # Number of decoder blocks (each block ~doubles the resolution)

data:
    dataset: 'rcc_dataset_transformer_dc'
    vocab_json: '/data/inseong/skrr/DIRL_Capstone/data_loader/LEVIR-MCI-dataset/images_flattened/annotations/transformer_vocab.json'
    h5_label_file: '/data/inseong/skrr/DIRL_Capstone/data_loader/LEVIR-MCI-dataset/images_flattened/annotations/transformer_labels.h5'
    default_feature_dir: '/data/inseong/skrr/DIRL_Capstone/data_loader/LEVIR-MCI-dataset/images_flattened/before_feature'
    semantic_feature_dir: '/data/inseong/skrr/DIRL_Capstone/data_loader/LEVIR-MCI-dataset/images_flattened/after_feature'
    default_img_dir: '/data/inseong/skrr/DIRL_Capstone/data_loader/LEVIR-MCI-dataset/images_flattened/before'
    semantic_img_dir: '/data/inseong/skrr/DIRL_Capstone/data_loader/LEVIR-MCI-dataset/images_flattened/after'
    splits_json: '/data/inseong/skrr/DIRL_Capstone/data_loader/LEVIR-MCI-dataset/images_flattened/annotations/split.json'
    train:
        batch_size: 128
train:
    max_iter: 13000
    snapshot_interval: 1000
    grad_clip: -1.0
    optim:
        type: 'adam'
        lr: 0.0002
        weight_decay: 0.0
